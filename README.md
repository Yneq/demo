# TradeXchange AI Assessment - Text-to-SQL Demo

Natural language interface for querying Logistics Performance Index (LPI) trade data.

è‡ªç„¶èªžè¨€ä»‹é¢ï¼Œç”¨æ–¼æŸ¥è©¢ç‰©æµç¸¾æ•ˆæŒ‡æ•¸ï¼ˆLPIï¼‰è²¿æ˜“æ•¸æ“šã€‚

---

## ðŸŽ¯ Solution Overview / è§£æ±ºæ–¹æ¡ˆæ¦‚è¿°

This solution provides a **web-based Text-to-SQL system** that:
1. Accepts natural language questions about trade data
2. Uses an LLM (via OpenRouter) to convert questions to SQL
3. Executes queries against a Supabase database
4. Displays results with data quality handling and error management

æ­¤è§£æ±ºæ–¹æ¡ˆæä¾›åŸºæ–¼ç¶²é çš„ **Text-to-SQL ç³»çµ±**ï¼š
1. æŽ¥å—é—œæ–¼è²¿æ˜“æ•¸æ“šçš„è‡ªç„¶èªžè¨€å•é¡Œ
2. ä½¿ç”¨ LLMï¼ˆé€éŽ OpenRouterï¼‰å°‡å•é¡Œè½‰æ›ç‚º SQL
3. å° Supabase è³‡æ–™åº«åŸ·è¡ŒæŸ¥è©¢
4. é¡¯ç¤ºçµæžœï¼Œä¸¦è™•ç†è³‡æ–™å“è³ªå•é¡Œèˆ‡éŒ¯èª¤ç®¡ç†

---

## ðŸ—ï¸ Tech Stack / æŠ€è¡“æ£§

- **Frontend**: Streamlit (Python-based web UI)
- **LLM Integration**: OpenRouter API (Claude 3.5 Sonnet)
- **Database**: Supabase (PostgreSQL)
- **Data Processing**: Pandas
- **HTTP Client**: Requests

---

## ðŸ“Š Database Schema / è³‡æ–™åº«çµæ§‹

**Table**: `countries_lpi`

| Column | Type | Description |
|--------|------|-------------|
| `id` | integer | Primary key |
| `country` | text | Country name |
| `region` | text | Geographic region |
| `lpi_score` | numeric | Logistics Performance Index (1.0-5.0) |
| `year` | integer | Year of data |

**Connection Details**:
- URL: `https://bqyrjnpwiwldppbkeafk.supabase.co`
- Access: Read-only (Anon key provided separately)

---

##  Quick Start / å¿«é€Ÿé–‹å§‹

### Prerequisites / å…ˆæ±ºæ¢ä»¶

- Python 3.12+
- Git

### Installation / å®‰è£
```bash
# 1. Clone the repository
git clone https://github.com/Yneq/demo.git
cd demo

# 2. Create virtual environment
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Set up environment variables
# Create .env file with:
# OPENROUTER_API_KEY=your_openrouter_key
# SUPABASE_URL=https://bqyrjnpwiwldppbkeafk.supabase.co
# SUPABASE_KEY=your_supabase_anon_key
```

### Running the Application / åŸ·è¡Œæ‡‰ç”¨ç¨‹å¼
```bash
# Start Streamlit app
streamlit run app.py

# Open browser at http://localhost:8501
```

### Running Tests / åŸ·è¡Œæ¸¬è©¦
```bash
# Test all three required queries
python tests/test_queries.py
```

---

## âœ… Required Queries Implementation / å¿…è¦æŸ¥è©¢å¯¦ä½œ

All three required queries are fully implemented and tested:

### Query 1: Asia Countries with LPI > 3.0
**Question**: "Which countries in Asia have an LPI score above 3.0?"

**Generated SQL**:
```sql
SELECT DISTINCT country, lpi_score, year 
FROM countries_lpi 
WHERE region LIKE '%Asia%' 
AND lpi_score > 3.0 
AND lpi_score IS NOT NULL 
ORDER BY lpi_score DESC;
```

**Result**: Returns Asian countries with scores above 3.0, sorted by performance.

---

### Query 2: Average LPI by Region
**Question**: "What's the average LPI score by region?"

**Generated SQL**:
```sql
SELECT region, ROUND(AVG(lpi_score)::numeric, 2) as avg_lpi_score 
FROM countries_lpi 
WHERE lpi_score IS NOT NULL 
GROUP BY region 
ORDER BY avg_lpi_score DESC;
```

**Result**: Calculates and displays average scores grouped by region.

---

### Query 3: Top 5 Countries
**Question**: "Show me the top 5 countries by logistics performance"

**Generated SQL**:
```sql
SELECT DISTINCT country, MAX(lpi_score) as max_lpi_score 
FROM countries_lpi 
WHERE lpi_score IS NOT NULL 
GROUP BY country 
ORDER BY max_lpi_score DESC 
LIMIT 5;
```

**Result**: Returns top 5 performing countries.

---

## ðŸ”§ Key Features / æ ¸å¿ƒåŠŸèƒ½

### 1. Data Quality Handling / è³‡æ–™å“è³ªè™•ç†

The database contains quality issues as mentioned in the requirements. Our solution handles:

**Problem**: Inconsistent data types
- Text values: `"three point six"` â†’ should be `3.6`
- Numeric values: `3.60`, `4.30` (already correct)
- Case inconsistencies: `"SINGAPORE"` vs `"Singapore"`

**Solution**: Robust data cleaning pipeline
```python
# Converts text numbers to numeric
"three point six" â†’ 3.6
"four point seven" â†’ 4.7

# Standardizes case
"SINGAPORE" â†’ "Singapore"
"asia" â†’ "Asia"

# Ensures numeric type
All lpi_score values converted to float
```

### 2. Error Handling / éŒ¯èª¤è™•ç†

Comprehensive error handling for:
- âœ… LLM API failures (timeout, rate limits)
- âœ… Database connection issues
- âœ… Invalid SQL generation
- âœ… Empty query results
- âœ… Data type conversion errors

### 3. User Interface / ä½¿ç”¨è€…ä»‹é¢

- ðŸŒ Bilingual (English/Chinese)
- ðŸ“ Example queries for quick testing
- ðŸ“Š Interactive result tables
- ðŸ“¥ CSV download functionality
- ðŸŽ¨ Clean, professional design

---

## ðŸ›ï¸ Project Structure / å°ˆæ¡ˆçµæ§‹
```
demo/
â”œâ”€â”€ app.py                      # Streamlit main application
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env                        # Environment variables (not in git)
â”œâ”€â”€ .gitignore                 # Git ignore rules
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ prompt.py              # LLM prompt engineering
â”‚   â”œâ”€â”€ llm.py                 # OpenRouter API integration
â”‚   â””â”€â”€ database.py            # Supabase query execution
â””â”€â”€ tests/
    â””â”€â”€ test_queries.py        # Automated query testing
```

---

## ðŸŽ¥ Demo Video / ç¤ºç¯„å½±ç‰‡

**Video Link**: [Insert your video link here]

**Duration**: ~2 minutes

**Contents**:
- Introduction
- Query 1 demonstration
- Query 2 demonstration
- Query 3 demonstration
- Error handling showcase

---

## ðŸ’¡ Technical Highlights / æŠ€è¡“äº®é»ž

### 1. Prompt Engineering
Carefully crafted system prompts with:
- Database schema description
- SQL syntax guidelines
- Few-shot examples
- Data quality warnings

### 2. Data Cleaning Pipeline
```python
def parse_lpi_score(value):
    """
    Handles multiple data formats:
    - Numeric: 4.30 â†’ 4.30
    - Text: "three point six" â†’ 3.6
    - Invalid: None â†’ None
    """
    # Improved logic with unified number mapping
    text_to_num = {
        'zero': 0, 'one': 1, 'two': 2, 'three': 3,
        'four': 4, 'five': 5, 'six': 6, 'seven': 7,
        'eight': 8, 'nine': 9
    }
    
    # "three point six" â†’ 3 + 0.6 = 3.6
    whole_val = text_to_num.get(whole_str, 0)
    decimal_val = text_to_num.get(decimal_str, 0) * 0.1
    return float(whole_val + decimal_val)
```

### 3. Fallback Strategy
Since Supabase Python SDK had version conflicts, implemented direct REST API calls:
- More reliable
- Better error handling
- Clearer code flow

---

## ðŸ§ª Testing / æ¸¬è©¦

All three required queries pass automated tests:
```bash
(.venv) $ python tests/test_queries.py

============================================================
Testing: Query 1 - Asia LPI > 3.0
âœ… Success! Found 14 results

============================================================
Testing: Query 2 - Average by Region
âœ… Success! Found 8 results

============================================================
Testing: Query 3 - Top 5
âœ… Success! Found 5 results

============================================================
SUMMARY
============================================================
âœ… PASS - Query 1 - Asia LPI > 3.0
âœ… PASS - Query 2 - Average by Region
âœ… PASS - Query 3 - Top 5

Total: 3/3 passed
============================================================
```

---

## ðŸ”’ Security / å®‰å…¨æ€§

- âœ… API keys stored in `.env` (not committed to git)
- âœ… Read-only database access
- âœ… Input sanitization via LLM
- âœ… No SQL injection risk (queries generated by AI, not concatenated)

---

## âš™ï¸ Configuration / è¨­å®š

### Environment Variables

Create a `.env` file in the project root:
```env
OPENROUTER_API_KEY=sk-or-v1-xxxxxxxxxxxxxxxx
SUPABASE_URL=https://bqyrjnpwiwldppbkeafk.supabase.co
SUPABASE_KEY=xxxxxxxxxxxxx...
```

### Model Selection

Default model: `anthropic/claude-3.5-sonnet`

To change models, edit `utils/llm.py`:
```python
def call_llm(prompt: str, model: str = "google/gemini-2.0-flash-exp:free"):
    # Switch to Gemini (free tier)
```

Available models: https://openrouter.ai/models

---

## ðŸ› Troubleshooting / ç–‘é›£æŽ’è§£

### Issue: "Client.__init__() got an unexpected keyword argument 'proxy'"
**Solution**: Use the provided `requirements.txt` which specifies compatible versions:
```txt
supabase==2.9.0
postgrest>=0.17.0, <0.18.0
```

### Issue: Empty results or type errors
**Solution**: The `clean_data()` function handles this automatically. Ensure it's called before query execution.

### Issue: LLM not generating correct SQL
**Solution**: Check the prompt in `utils/prompt.py`. Ensure examples match your query pattern.

---

## ðŸ“ˆ Future Improvements / æœªä¾†æ”¹é€²

If given more time, I would add:

1. **Caching**: Cache LLM responses to reduce API costs
2. **Query History**: Store previous queries in session state
3. **Advanced Filters**: More complex query building
4. **Visualization**: Charts and graphs for results
5. **Multi-language Support**: Extended language support beyond EN/ZH

---

## ðŸ“ Development Notes / é–‹ç™¼ç­†è¨˜

### Challenges Encountered / é‡åˆ°çš„æŒ‘æˆ°

1. **Supabase SDK Version Conflict**
   - Issue: `supabase-py` had breaking changes
   - Solution: Switched to direct REST API calls

2. **Data Quality Issues**
   - Issue: Mixed data types (`"three point six"` vs `4.30`)
   - Solution: Robust parsing with text-to-number conversion

3. **SQL Generation Reliability**
   - Issue: LLM sometimes adds markdown formatting
   - Solution: Strip code blocks before execution

### Time Spent / è€—æ™‚

- Planning & Setup: 30 min
- Core Implementation: 2 hours
- Testing & Refinement: 1 hour
- Documentation & Video: 30 min
- **Total**: ~4 hours

---

## ðŸ‘¨â€ðŸ’» Author / ä½œè€…

**Vance**
- GitHub: [@Yneq](https://github.com/Yneq)
- Repository: [demo](https://github.com/Yneq/demo)

---

## ðŸ“„ License / æŽˆæ¬Š

This project is created for the TradeXchange AI assessment.

æ­¤å°ˆæ¡ˆç‚º TradeXchange AI è©•ä¼°ä½œæ¥­æ‰€å»ºç«‹ã€‚

---

## ðŸ™ Acknowledgments / è‡´è¬

- OpenRouter for LLM API access
- Supabase for database hosting
- Streamlit for rapid UI development

---


*Last Updated: February 2026*